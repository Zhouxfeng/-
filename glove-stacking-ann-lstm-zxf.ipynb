{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # 线性代数\nimport pandas as pd # 数据处理，CSV文件I/O（例如pd.read\\U CSV）\n\n#输入数据文件位于只读的“./Input/”目录中\n#例如，运行此命令（通过单击run或按Shift+Enter）将列出输入目录下的所有文件\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-26T07:27:52.748518Z","iopub.execute_input":"2021-05-26T07:27:52.74923Z","iopub.status.idle":"2021-05-26T07:27:52.76844Z","shell.execute_reply.started":"2021-05-26T07:27:52.749139Z","shell.execute_reply":"2021-05-26T07:27:52.767373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1、导入相关库","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom wordcloud import WordCloud, STOPWORDS\nimport seaborn as sns\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.util import ngrams\nfrom textblob import TextBlob, Word\nimport collections\nimport re\nimport string\nimport emoji\nimport time\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import StackingClassifier\nimport xgboost\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import f1_score\n\nimport tensorflow as tf\nfrom collections import Counter\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:27:52.770049Z","iopub.execute_input":"2021-05-26T07:27:52.770584Z","iopub.status.idle":"2021-05-26T07:28:01.286802Z","shell.execute_reply.started":"2021-05-26T07:27:52.770519Z","shell.execute_reply":"2021-05-26T07:28:01.285788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:01.288906Z","iopub.execute_input":"2021-05-26T07:28:01.289315Z","iopub.status.idle":"2021-05-26T07:28:01.384993Z","shell.execute_reply.started":"2021-05-26T07:28:01.289271Z","shell.execute_reply":"2021-05-26T07:28:01.38383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2、探测性数据分析","metadata":{}},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:01.386739Z","iopub.execute_input":"2021-05-26T07:28:01.387015Z","iopub.status.idle":"2021-05-26T07:28:01.392937Z","shell.execute_reply.started":"2021-05-26T07:28:01.386988Z","shell.execute_reply":"2021-05-26T07:28:01.391898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2.1训练集数据等级分布","metadata":{}},{"cell_type":"code","source":"train_df[\"target\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:01.394512Z","iopub.execute_input":"2021-05-26T07:28:01.394964Z","iopub.status.idle":"2021-05-26T07:28:01.410033Z","shell.execute_reply.started":"2021-05-26T07:28:01.394924Z","shell.execute_reply":"2021-05-26T07:28:01.408865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"target\"].value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:01.413456Z","iopub.execute_input":"2021-05-26T07:28:01.413756Z","iopub.status.idle":"2021-05-26T07:28:01.440631Z","shell.execute_reply.started":"2021-05-26T07:28:01.413725Z","shell.execute_reply":"2021-05-26T07:28:01.439749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"countplot = sns.countplot(x=\"target\", data=train_df, palette=\"Set1\")\ncountplot.set_title(\"Real disaster tweets count\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:01.444829Z","iopub.execute_input":"2021-05-26T07:28:01.445124Z","iopub.status.idle":"2021-05-26T07:28:01.593201Z","shell.execute_reply.started":"2021-05-26T07:28:01.445096Z","shell.execute_reply":"2021-05-26T07:28:01.592303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_labels=[\"Non-Disaster\", \"Disaster\"]\nplt.pie(train_df['target'].value_counts(), labels=my_labels, colors = [\"Blue\",\"Red\"])\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:01.594713Z","iopub.execute_input":"2021-05-26T07:28:01.595003Z","iopub.status.idle":"2021-05-26T07:28:01.7484Z","shell.execute_reply.started":"2021-05-26T07:28:01.594976Z","shell.execute_reply":"2021-05-26T07:28:01.747339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.drop(columns=['id','keyword','location'], axis=1, inplace=True)\ntest_df.drop(columns=['keyword','location'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:01.749558Z","iopub.execute_input":"2021-05-26T07:28:01.749845Z","iopub.status.idle":"2021-05-26T07:28:01.75867Z","shell.execute_reply.started":"2021-05-26T07:28:01.749817Z","shell.execute_reply":"2021-05-26T07:28:01.757608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2.2词云","metadata":{}},{"cell_type":"markdown","source":"2.2.1 Wordcloud用于真实灾难推文","metadata":{}},{"cell_type":"code","source":"ax = plt.figure(figsize=(20,20))\nwordcloud = WordCloud(max_words = 500 , width = 1000 , height = 500 , stopwords = STOPWORDS).generate(\" \".join(train_df[train_df.target == 1].text))\nplt.imshow(wordcloud , interpolation = 'bilinear')","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:01.760062Z","iopub.execute_input":"2021-05-26T07:28:01.760428Z","iopub.status.idle":"2021-05-26T07:28:04.848918Z","shell.execute_reply.started":"2021-05-26T07:28:01.760338Z","shell.execute_reply":"2021-05-26T07:28:04.847712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2.2.2用于非灾难推特的Wordcloud","metadata":{}},{"cell_type":"code","source":"ax = plt.figure(figsize=(20,20))\nwordcloud = WordCloud(max_words = 500 , width = 1000 , height = 500 , stopwords = STOPWORDS).generate(\" \".join(train_df[train_df.target == 0].text))\nplt.imshow(wordcloud , interpolation = 'bilinear')","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:04.849966Z","iopub.execute_input":"2021-05-26T07:28:04.85025Z","iopub.status.idle":"2021-05-26T07:28:07.86673Z","shell.execute_reply.started":"2021-05-26T07:28:04.850222Z","shell.execute_reply":"2021-05-26T07:28:07.865567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3、预处理","metadata":{}},{"cell_type":"markdown","source":"3.1定义变量","metadata":{}},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\ncontraction_map = {\n\"ain't\": \"is not\",\n\"aren't\": \"are not\",\n\"can't\": \"cannot\",\n\"can't've\": \"cannot have\",\n\"'cause\": \"because\",\n\"could've\": \"could have\",\n\"couldn't\": \"could not\",\n\"couldn't've\": \"could not have\",\n\"didn't\": \"did not\",\n\"doesn't\": \"does not\",\n\"don't\": \"do not\",\n\"hadn't\": \"had not\",\n\"hadn't've\": \"had not have\",\n\"hasn't\": \"has not\",\n\"haven't\": \"have not\",\n\"he'd\": \"he would\",\n\"he'd've\": \"he would have\",\n\"he'll\": \"he will\",\n\"he'll've\": \"he he will have\",\n\"he's\": \"he is\",\n\"how'd\": \"how did\",\n\"how'd'y\": \"how do you\",\n\"how'll\": \"how will\",\n\"how's\": \"how is\",\n\"I'd\": \"I would\",\n\"I'd've\": \"I would have\",\n\"I'll\": \"I will\",\n\"I'll've\": \"I will have\",\n\"I'm\": \"I am\",\n\"I've\": \"I have\",\n\"i'd\": \"i would\",\n\"i'd've\": \"i would have\",\n\"i'll\": \"i will\",\n\"i'll've\": \"i will have\",\n\"i'm\": \"i am\",\n\"i've\": \"i have\",\n\"isn't\": \"is not\",\n\"it'd\": \"it would\",\n\"it'd've\": \"it would have\",\n\"it'll\": \"it will\",\n\"it'll've\": \"it will have\",\n\"it's\": \"it is\",\n\"let's\": \"let us\",\n\"ma'am\": \"madam\",\n\"mayn't\": \"may not\",\n\"might've\": \"might have\",\n\"mightn't\": \"might not\",\n\"mightn't've\": \"might not have\",\n\"must've\": \"must have\",\n\"mustn't\": \"must not\",\n\"mustn't've\": \"must not have\",\n\"needn't\": \"need not\",\n\"needn't've\": \"need not have\",\n\"o'clock\": \"of the clock\",\n\"oughtn't\": \"ought not\",\n\"oughtn't've\": \"ought not have\",\n\"shan't\": \"shall not\",\n\"sha'n't\": \"shall not\",\n\"shan't've\": \"shall not have\",\n\"she'd\": \"she would\",\n\"she'd've\": \"she would have\",\n\"she'll\": \"she will\",\n\"she'll've\": \"she will have\",\n\"she's\": \"she is\",\n\"should've\": \"should have\",\n\"shouldn't\": \"should not\",\n\"shouldn't've\": \"should not have\",\n\"so've\": \"so have\",\n\"so's\": \"so as\",\n\"that'd\": \"that would\",\n\"that'd've\": \"that would have\",\n\"that's\": \"that is\",\n\"there'd\": \"there would\",\n\"there'd've\": \"there would have\",\n\"there's\": \"there is\",\n\"they'd\": \"they would\",\n\"they'd've\": \"they would have\",\n\"they'll\": \"they will\",\n\"they'll've\": \"they will have\",\n\"they're\": \"they are\",\n\"they've\": \"they have\",\n\"to've\": \"to have\",\n\"wasn't\": \"was not\",\n\"we'd\": \"we would\",\n\"we'd've\": \"we would have\",\n\"we'll\": \"we will\",\n\"we'll've\": \"we will have\",\n\"we're\": \"we are\",\n\"we've\": \"we have\",\n\"weren't\": \"were not\",\n\"what'll\": \"what will\",\n\"what'll've\": \"what will have\",\n\"what're\": \"what are\",\n\"what's\": \"what is\",\n\"what've\": \"what have\",\n\"when's\": \"when is\",\n\"when've\": \"when have\",\n\"where'd\": \"where did\",\n\"where's\": \"where is\",\n\"where've\": \"where have\",\n\"who'll\": \"who will\",\n\"who'll've\": \"who will have\",\n\"who's\": \"who is\",\n\"who've\": \"who have\",\n\"why's\": \"why is\",\n\"why've\": \"why have\",\n\"will've\": \"will have\",\n\"won't\": \"will not\",\n\"won't've\": \"will not have\",\n\"would've\": \"would have\",\n\"wouldn't\": \"would not\",\n\"wouldn't've\": \"would not have\",\n\"y'all\": \"you all\",\n\"y'all'd\": \"you all would\",\n\"y'all'd've\": \"you all would have\",\n\"y'all're\": \"you all are\",\n\"y'all've\": \"you all have\",\n\"you'd\": \"you would\",\n\"you'd've\": \"you would have\",\n\"you'll\": \"you will\",\n\"you'll've\": \"you will have\",\n\"you're\": \"you are\",\n\"you've\": \"you have\",\n}\n\nall_punctuation = set(string.punctuation)\nall_punctuation.add(\"...\")\nall_punctuation.add('’')\nall_punctuation.add('-')\nall_punctuation.add('“')\nall_punctuation.add('[')\nall_punctuation.add(']')\nall_punctuation.add(' ')","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:07.868115Z","iopub.execute_input":"2021-05-26T07:28:07.868456Z","iopub.status.idle":"2021-05-26T07:28:07.90132Z","shell.execute_reply.started":"2021-05-26T07:28:07.868421Z","shell.execute_reply":"2021-05-26T07:28:07.899904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"需要创建一些函数，以便更容易实现它们","metadata":{}},{"cell_type":"markdown","source":"3.2、辅助函数","metadata":{}},{"cell_type":"code","source":"def uncapitalize(text):\n    return text.lower()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:07.902798Z","iopub.execute_input":"2021-05-26T07:28:07.903117Z","iopub.status.idle":"2021-05-26T07:28:07.907221Z","shell.execute_reply.started":"2021-05-26T07:28:07.903085Z","shell.execute_reply":"2021-05-26T07:28:07.906082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n3.2.1删除表情符号","metadata":{}},{"cell_type":"code","source":"def removeEmojis(text):\n    allchars = [c for c in text]\n    emoji_list = [c for c in allchars if c in emoji.UNICODE_EMOJI[\"en\"]]\n    clean_text = ' '.join([str for str in text.split() if not any(i in str for i in emoji_list)])\n    return clean_text","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:07.908417Z","iopub.execute_input":"2021-05-26T07:28:07.908789Z","iopub.status.idle":"2021-05-26T07:28:07.920522Z","shell.execute_reply.started":"2021-05-26T07:28:07.908757Z","shell.execute_reply":"2021-05-26T07:28:07.919659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3.2.2扩展缩写","metadata":{}},{"cell_type":"code","source":"def expand_abbr(article):\n    new_article = article\n    for item in contraction_map:\n        if item in article:\n            new_article = article.replace(item,contraction_map[item])\n    return new_article","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:07.921648Z","iopub.execute_input":"2021-05-26T07:28:07.921992Z","iopub.status.idle":"2021-05-26T07:28:07.940755Z","shell.execute_reply.started":"2021-05-26T07:28:07.921963Z","shell.execute_reply":"2021-05-26T07:28:07.939694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3.2.3删除网站URL","metadata":{}},{"cell_type":"code","source":"def strip_links(text):\n    link_regex    = re.compile('((https?):((//)|(\\\\\\\\))+([\\w\\d:#@%/;$()~_?\\+-=\\\\\\.&](#!)?)*)', re.DOTALL)\n    links         = re.findall(link_regex, text)\n    for link in links:\n        text = text.replace(link[0], ', ')    \n    return text","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:07.942Z","iopub.execute_input":"2021-05-26T07:28:07.942298Z","iopub.status.idle":"2021-05-26T07:28:07.955248Z","shell.execute_reply.started":"2021-05-26T07:28:07.942268Z","shell.execute_reply":"2021-05-26T07:28:07.954368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3.2.4剥离所有实体","metadata":{}},{"cell_type":"code","source":"def strip_all_entities(text):\n    entity_prefixes = ['@','#']\n    for separator in  string.punctuation:\n        if separator not in entity_prefixes :\n            text = text.replace(separator,' ')\n    words = []\n    for word in text.split():\n        word = word.strip()\n        if word:\n            if word[0] not in entity_prefixes:\n                words.append(word)\n    return ' '.join(words)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:07.956454Z","iopub.execute_input":"2021-05-26T07:28:07.956744Z","iopub.status.idle":"2021-05-26T07:28:07.968777Z","shell.execute_reply.started":"2021-05-26T07:28:07.956717Z","shell.execute_reply":"2021-05-26T07:28:07.967867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lemmatize_with_postag(text):\n    sent = TextBlob(text)\n    tag_dict = {\"J\": 'a', \n                \"N\": 'n', \n                \"V\": 'v', \n                \"R\": 'r'}\n    words_and_tags = [(w, tag_dict.get(pos[0], 'n')) for w, pos in sent.tags]    \n    lemmatized_list = [wd.lemmatize(tag) for wd, tag in words_and_tags]\n    return \" \".join(lemmatized_list)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:07.970398Z","iopub.execute_input":"2021-05-26T07:28:07.971145Z","iopub.status.idle":"2021-05-26T07:28:07.985017Z","shell.execute_reply.started":"2021-05-26T07:28:07.971095Z","shell.execute_reply":"2021-05-26T07:28:07.983934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3.2.5删除停止字","metadata":{}},{"cell_type":"code","source":"def remove_stopwords(text):\n    stop_words = set(stopwords.words('english'))\n    word_tokens = word_tokenize(text)\n    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n    return filtered_sentence","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:07.989199Z","iopub.execute_input":"2021-05-26T07:28:07.989558Z","iopub.status.idle":"2021-05-26T07:28:08.001109Z","shell.execute_reply.started":"2021-05-26T07:28:07.989526Z","shell.execute_reply":"2021-05-26T07:28:07.999757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3.2.6删除标点符号","metadata":{}},{"cell_type":"code","source":"def remove_punctuation(token_list):\n    new_list = []\n    for tok in token_list:\n        if tok not in all_punctuation:\n            new_list.append(tok)\n    final_list = [x for x in new_list if not (x.isdigit() or x[0] == '-' and x[1:].isdigit())]\n    final_sentence = \" \".join(final_list)\n    return final_sentence","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:08.004604Z","iopub.execute_input":"2021-05-26T07:28:08.005444Z","iopub.status.idle":"2021-05-26T07:28:08.014848Z","shell.execute_reply.started":"2021-05-26T07:28:08.005383Z","shell.execute_reply":"2021-05-26T07:28:08.013917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3.3清理文本","metadata":{}},{"cell_type":"code","source":"def clean_text(text):\n    text = uncapitalize(text)\n    text = removeEmojis(text)\n    text = expand_abbr(text)\n    text = strip_links(text)\n    text = strip_all_entities(text)\n    text = lemmatize_with_postag(text)\n    cleaned_tokens = remove_stopwords(text)\n    final_text = remove_punctuation(cleaned_tokens)\n    return final_text\nprocessed_train_df = train_df.copy(deep=True)\nprocessed_train_df[\"text\"] = processed_train_df.text.apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:08.016529Z","iopub.execute_input":"2021-05-26T07:28:08.0173Z","iopub.status.idle":"2021-05-26T07:28:26.401056Z","shell.execute_reply.started":"2021-05-26T07:28:08.017248Z","shell.execute_reply":"2021-05-26T07:28:26.400335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:26.402059Z","iopub.execute_input":"2021-05-26T07:28:26.402463Z","iopub.status.idle":"2021-05-26T07:28:26.411144Z","shell.execute_reply.started":"2021-05-26T07:28:26.402433Z","shell.execute_reply":"2021-05-26T07:28:26.410381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"现在进行更多的可视化，以便更容易去理解数据","metadata":{}},{"cell_type":"markdown","source":"# 4、进一步可视化","metadata":{}},{"cell_type":"markdown","source":"## 4.1 Wordclouds ","metadata":{}},{"cell_type":"markdown","source":"## 词云","metadata":{}},{"cell_type":"markdown","source":"### 4.1.1 Wordcloud用于真实灾难推文","metadata":{}},{"cell_type":"code","source":"ax = plt.figure(figsize=(20,20))\nwordcloud = WordCloud(max_words = 500, width = 1000, height = 500).generate(\" \".join(processed_train_df[processed_train_df.target == 1].text))\nplt.imshow(wordcloud , interpolation = 'bilinear')","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:26.412151Z","iopub.execute_input":"2021-05-26T07:28:26.412545Z","iopub.status.idle":"2021-05-26T07:28:29.604866Z","shell.execute_reply.started":"2021-05-26T07:28:26.412513Z","shell.execute_reply":"2021-05-26T07:28:29.60363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.1.2用于非灾难性推文的Wordcloud","metadata":{}},{"cell_type":"code","source":"ax = plt.figure(figsize=(20,20))\nwordcloud = WordCloud(max_words = 500, width = 1000, height = 500).generate(\" \".join(processed_train_df[processed_train_df.target == 0].text))\nplt.imshow(wordcloud , interpolation = 'bilinear')","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:29.606298Z","iopub.execute_input":"2021-05-26T07:28:29.606726Z","iopub.status.idle":"2021-05-26T07:28:32.785155Z","shell.execute_reply.started":"2021-05-26T07:28:29.606682Z","shell.execute_reply":"2021-05-26T07:28:32.77725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2、n-grams处理真实性灾难推文","metadata":{}},{"cell_type":"markdown","source":"### 4.2.1预处理","metadata":{}},{"cell_type":"code","source":"def extract_ngrams(text, num):\n    n_grams = ngrams(nltk.word_tokenize(text), num)\n    return [' '.join(grams) for grams in n_grams]","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:32.786972Z","iopub.execute_input":"2021-05-26T07:28:32.787399Z","iopub.status.idle":"2021-05-26T07:28:32.793634Z","shell.execute_reply.started":"2021-05-26T07:28:32.78734Z","shell.execute_reply":"2021-05-26T07:28:32.792469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"disaster_text = \" \".join(processed_train_df[processed_train_df.target == 1].text)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:32.795207Z","iopub.execute_input":"2021-05-26T07:28:32.795687Z","iopub.status.idle":"2021-05-26T07:28:32.807279Z","shell.execute_reply.started":"2021-05-26T07:28:32.795631Z","shell.execute_reply":"2021-05-26T07:28:32.806154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2.2Uni-grams（最多相同单词）","metadata":{}},{"cell_type":"code","source":"real_one_gram = extract_ngrams(disaster_text, 1)\nreal_one_gram_freq = collections.Counter(real_one_gram)\nreal_one_gram_freq.most_common(15)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:32.808703Z","iopub.execute_input":"2021-05-26T07:28:32.809139Z","iopub.status.idle":"2021-05-26T07:28:33.092075Z","shell.execute_reply.started":"2021-05-26T07:28:32.809093Z","shell.execute_reply":"2021-05-26T07:28:33.090938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"freq_list = real_one_gram_freq.most_common(15)\nfig,ax = plt.subplots()\n\nfig = plt.figure(figsize=(10,10))\nx = []\ny = []\nfor item in freq_list:\n    x.append(item[0])\n    y.append(item[1])\n    \nax.vlines(x,ymin=8, ymax=y, color=\"green\")\nax.plot(x,y, \"o\", color=\"maroon\")\nax.set_xticklabels(x, rotation=90)\nax.set_ylabel(\"count\")\nax.set_title(\"unigram of real disaster tweets\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:33.093241Z","iopub.execute_input":"2021-05-26T07:28:33.093556Z","iopub.status.idle":"2021-05-26T07:28:33.283222Z","shell.execute_reply.started":"2021-05-26T07:28:33.093527Z","shell.execute_reply":"2021-05-26T07:28:33.28231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2.3 Bi-grams","metadata":{}},{"cell_type":"code","source":"real_bigram = extract_ngrams(disaster_text, 2)\nreal_bigram_freq = collections.Counter(real_bigram)\nreal_bigram_freq.most_common(15)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:33.284563Z","iopub.execute_input":"2021-05-26T07:28:33.284866Z","iopub.status.idle":"2021-05-26T07:28:33.570849Z","shell.execute_reply.started":"2021-05-26T07:28:33.284835Z","shell.execute_reply":"2021-05-26T07:28:33.569296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"freq_list = real_bigram_freq.most_common(15)\nfig,ax = plt.subplots()\n\nfig = plt.figure(figsize=(10,10))\nx = []\ny = []\nfor item in freq_list:\n    x.append(item[0])\n    y.append(item[1])\n    \nax.vlines(x,ymin=8, ymax=y, color=\"green\")\nax.plot(x,y, \"o\", color=\"maroon\")\nax.set_xticklabels(x, rotation=90)\nax.set_ylabel(\"count\")\nax.set_title(\"bigram of real disaster tweets\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:33.574433Z","iopub.execute_input":"2021-05-26T07:28:33.574855Z","iopub.status.idle":"2021-05-26T07:28:33.783183Z","shell.execute_reply.started":"2021-05-26T07:28:33.574813Z","shell.execute_reply":"2021-05-26T07:28:33.782222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2.4 Tri-grams","metadata":{}},{"cell_type":"code","source":"real_trigram = extract_ngrams(disaster_text, 3)\nreal_trigram_freq = collections.Counter(real_trigram)\nreal_trigram_freq.most_common(15)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:33.784444Z","iopub.execute_input":"2021-05-26T07:28:33.784731Z","iopub.status.idle":"2021-05-26T07:28:34.068476Z","shell.execute_reply.started":"2021-05-26T07:28:33.784702Z","shell.execute_reply":"2021-05-26T07:28:34.067469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"freq_list = real_trigram_freq.most_common(15)\nfig,ax = plt.subplots()\n\nfig = plt.figure(figsize=(10,10))\nx = []\ny = []\nfor item in freq_list:\n    x.append(item[0])\n    y.append(item[1])\n    \nax.vlines(x,ymin=8, ymax=y, color=\"green\")\nax.plot(x,y, \"o\", color=\"maroon\")\nax.set_xticklabels(x, rotation=90)\nax.set_ylabel(\"count\")\nax.set_title(\"trigram of real disaster tweets\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:34.069824Z","iopub.execute_input":"2021-05-26T07:28:34.070114Z","iopub.status.idle":"2021-05-26T07:28:34.291303Z","shell.execute_reply.started":"2021-05-26T07:28:34.070086Z","shell.execute_reply":"2021-05-26T07:28:34.290251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.3 n-grams 处理非灾害性推文","metadata":{}},{"cell_type":"markdown","source":"### 4.3.1预处理","metadata":{}},{"cell_type":"code","source":"non_disaster_text = \" \".join(processed_train_df[processed_train_df.target == 0].text)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:34.292848Z","iopub.execute_input":"2021-05-26T07:28:34.293183Z","iopub.status.idle":"2021-05-26T07:28:34.300959Z","shell.execute_reply.started":"2021-05-26T07:28:34.293152Z","shell.execute_reply":"2021-05-26T07:28:34.299904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.3.2Uni-grams（最多相同单词）","metadata":{}},{"cell_type":"code","source":"non_disaster_one_gram = extract_ngrams(non_disaster_text, 1)\nnon_disaster_one_gram_freq = collections.Counter(non_disaster_one_gram)\nnon_disaster_one_gram_freq.most_common(15)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:34.302457Z","iopub.execute_input":"2021-05-26T07:28:34.302862Z","iopub.status.idle":"2021-05-26T07:28:34.622116Z","shell.execute_reply.started":"2021-05-26T07:28:34.302811Z","shell.execute_reply":"2021-05-26T07:28:34.620943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"freq_list = non_disaster_one_gram_freq.most_common(15)\nfig,ax = plt.subplots()\n\nfig = plt.figure(figsize=(10,10))\nx = []\ny = []\nfor item in freq_list:\n    x.append(item[0])\n    y.append(item[1])\n    \nax.vlines(x,ymin=8, ymax=y, color=\"green\")\nax.plot(x,y, \"o\", color=\"maroon\")\nax.set_xticklabels(x, rotation=45)\nax.set_ylabel(\"count\")\nax.set_title(\"unigram of non-disaster tweets\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:34.625333Z","iopub.execute_input":"2021-05-26T07:28:34.625646Z","iopub.status.idle":"2021-05-26T07:28:34.820292Z","shell.execute_reply.started":"2021-05-26T07:28:34.625617Z","shell.execute_reply":"2021-05-26T07:28:34.819221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.3.3 Bi-grams","metadata":{}},{"cell_type":"code","source":"non_disaster_bigram = extract_ngrams(non_disaster_text, 2)\nnon_disaster_bigram_freq = collections.Counter(non_disaster_bigram)\nnon_disaster_bigram_freq.most_common(15)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:34.821481Z","iopub.execute_input":"2021-05-26T07:28:34.821757Z","iopub.status.idle":"2021-05-26T07:28:35.147618Z","shell.execute_reply.started":"2021-05-26T07:28:34.82173Z","shell.execute_reply":"2021-05-26T07:28:35.146932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"freq_list = non_disaster_bigram_freq.most_common(15)\nfig,ax = plt.subplots()\n\nfig = plt.figure(figsize=(18,1))\nx = []\ny = []\nfor item in freq_list:\n    x.append(item[0])\n    y.append(item[1])\n    \nax.vlines(x,ymin=8, ymax=y, color=\"green\")\nax.plot(x,y, \"o\", color=\"maroon\")\nax.set_xticklabels(x, rotation=90)\nax.set_ylabel(\"count\")\nax.set_title(\"bigram of non-disaster tweets\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:35.148624Z","iopub.execute_input":"2021-05-26T07:28:35.149027Z","iopub.status.idle":"2021-05-26T07:28:35.362001Z","shell.execute_reply.started":"2021-05-26T07:28:35.148985Z","shell.execute_reply":"2021-05-26T07:28:35.361029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.3.4 Tri-grams","metadata":{}},{"cell_type":"code","source":"non_disaster_trigram = extract_ngrams(non_disaster_text, 3)\nnon_disaster_trigram_freq = collections.Counter(non_disaster_trigram)\nnon_disaster_trigram_freq.most_common(15)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:35.363292Z","iopub.execute_input":"2021-05-26T07:28:35.363616Z","iopub.status.idle":"2021-05-26T07:28:35.689187Z","shell.execute_reply.started":"2021-05-26T07:28:35.363584Z","shell.execute_reply":"2021-05-26T07:28:35.688312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"freq_list = non_disaster_trigram_freq.most_common(15)\nfig,ax = plt.subplots()\n\nfig = plt.figure(figsize=(10,10))\nx = []\ny = []\nfor item in freq_list:\n    x.append(item[0])\n    y.append(item[1])\n    \nax.vlines(x,ymin=8, ymax=y, color=\"green\")\nax.plot(x,y, \"o\", color=\"maroon\")\nax.set_xticklabels(x, rotation=90)\nax.set_ylabel(\"count\")\nax.set_title(\"trigram of non-disaster tweets\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:35.690508Z","iopub.execute_input":"2021-05-26T07:28:35.690784Z","iopub.status.idle":"2021-05-26T07:28:35.919084Z","shell.execute_reply.started":"2021-05-26T07:28:35.690757Z","shell.execute_reply":"2021-05-26T07:28:35.918103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.导入单词，嵌入Glove预训练词向量文件","metadata":{}},{"cell_type":"code","source":"embedding_df = processed_train_df.copy(deep=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:35.920417Z","iopub.execute_input":"2021-05-26T07:28:35.920719Z","iopub.status.idle":"2021-05-26T07:28:35.92487Z","shell.execute_reply.started":"2021-05-26T07:28:35.920688Z","shell.execute_reply":"2021-05-26T07:28:35.923901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_embeddings = {}\nf = open('/kaggle/input/glove6b/glove.6B.100d.txt', encoding='utf-8')\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    word_embeddings[word] = coefs","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:35.926135Z","iopub.execute_input":"2021-05-26T07:28:35.926531Z","iopub.status.idle":"2021-05-26T07:28:53.533698Z","shell.execute_reply.started":"2021-05-26T07:28:35.926492Z","shell.execute_reply":"2021-05-26T07:28:53.532815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6.将句子转化为向量","metadata":{}},{"cell_type":"code","source":"def get_sentence_vectors(text):\n    sentence_vector = np.zeros((100,))\n    if len(text) == 0:\n        return sentence_vector\n    else:\n        tokens = text.split()\n        for token in tokens:\n            try:\n                sentence_vector += word_embeddings[token]\n            except:\n                pass\n        sentence_vector = sentence_vector/len(tokens)\n        return sentence_vector","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:53.535205Z","iopub.execute_input":"2021-05-26T07:28:53.535924Z","iopub.status.idle":"2021-05-26T07:28:53.542639Z","shell.execute_reply.started":"2021-05-26T07:28:53.535878Z","shell.execute_reply":"2021-05-26T07:28:53.541919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_df[\"text\"] = embedding_df.text.apply(get_sentence_vectors)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:53.544178Z","iopub.execute_input":"2021-05-26T07:28:53.544894Z","iopub.status.idle":"2021-05-26T07:28:53.76767Z","shell.execute_reply.started":"2021-05-26T07:28:53.544846Z","shell.execute_reply":"2021-05-26T07:28:53.766655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:53.769208Z","iopub.execute_input":"2021-05-26T07:28:53.769769Z","iopub.status.idle":"2021-05-26T07:28:53.791325Z","shell.execute_reply.started":"2021-05-26T07:28:53.769723Z","shell.execute_reply":"2021-05-26T07:28:53.790408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7.机器学习模型，对F1进行计算（精度和查全率的加权平均值）","metadata":{}},{"cell_type":"markdown","source":"## 7.1训练集合测试集分割","metadata":{}},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(embedding_df[\"text\"],embedding_df[\"target\"],test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:53.792847Z","iopub.execute_input":"2021-05-26T07:28:53.793352Z","iopub.status.idle":"2021-05-26T07:28:53.808254Z","shell.execute_reply.started":"2021-05-26T07:28:53.793287Z","shell.execute_reply":"2021-05-26T07:28:53.807242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.2朴素贝叶斯","metadata":{}},{"cell_type":"code","source":"print(f\"**********Naive Bayes**********\")\nmodel =  GaussianNB()\nstart = time.time()\nmodel.fit(x_train.to_list(),y_train)\ny_pred = model.predict(x_test.to_list())\nf1score = f1_score(y_test,y_pred)\naccuracyscore = accuracy_score(y_test,y_pred)\nprecisionscore = precision_score(y_test,y_pred)\nrecallscore = recall_score(y_test,y_pred)\nprint(f\"f1_score: {f1score}\")\nprint(f\"Accuracy: {accuracyscore}\")\nprint(f\"Precision: {precisionscore}\")\nprint(f\"Recall: {recallscore}\")\nprint('Time Taken :' + str(round(start - time.time(),2) * -1))\nprint(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:53.809618Z","iopub.execute_input":"2021-05-26T07:28:53.809977Z","iopub.status.idle":"2021-05-26T07:28:53.85543Z","shell.execute_reply.started":"2021-05-26T07:28:53.809945Z","shell.execute_reply":"2021-05-26T07:28:53.854332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.3逻辑回归","metadata":{}},{"cell_type":"code","source":"print(f\"**********Logistic Regression**********\")\nmodel = LogisticRegression()\nstart = time.time()\nmodel.fit(x_train.to_list(),y_train)\ny_pred = model.predict(x_test.to_list())\nf1score = f1_score(y_test,y_pred)\naccuracyscore = accuracy_score(y_test,y_pred)\nprecisionscore = precision_score(y_test,y_pred)\nrecallscore = recall_score(y_test,y_pred)\nprint(f\"f1_score: {f1score}\")\nprint(f\"Accuracy: {accuracyscore}\")\nprint(f\"Precision: {precisionscore}\")\nprint(f\"Recall: {recallscore}\")\nprint('Time Taken :' + str(round(start - time.time(),2) * -1))\nprint(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:53.856682Z","iopub.execute_input":"2021-05-26T07:28:53.857Z","iopub.status.idle":"2021-05-26T07:28:54.038969Z","shell.execute_reply.started":"2021-05-26T07:28:53.856969Z","shell.execute_reply":"2021-05-26T07:28:54.037824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.4随机森林","metadata":{}},{"cell_type":"code","source":"print(f\"**********Random Forest**********\")\nmodel = RandomForestClassifier()\nstart = time.time()\nmodel.fit(x_train.to_list(),y_train)\ny_pred = model.predict(x_test.to_list())\nf1score = f1_score(y_test,y_pred)\naccuracyscore = accuracy_score(y_test,y_pred)\nprecisionscore = precision_score(y_test,y_pred)\nrecallscore = recall_score(y_test,y_pred)\nprint(f\"f1_score: {f1score}\")\nprint(f\"Accuracy: {accuracyscore}\")\nprint(f\"Precision: {precisionscore}\")\nprint(f\"Recall: {recallscore}\")\nprint('Time Taken :' + str(round(start - time.time(),2) * -1))\nprint(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:54.040672Z","iopub.execute_input":"2021-05-26T07:28:54.041345Z","iopub.status.idle":"2021-05-26T07:28:59.334895Z","shell.execute_reply.started":"2021-05-26T07:28:54.041288Z","shell.execute_reply":"2021-05-26T07:28:59.333844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.5 AdaBoost（迭代）","metadata":{}},{"cell_type":"markdown","source":"核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器（强分类器）","metadata":{}},{"cell_type":"code","source":"print(f\"**********AdaBoost**********\")\nmodel = AdaBoostClassifier()\nstart = time.time()\nmodel.fit(x_train.to_list(),y_train)\ny_pred = model.predict(x_test.to_list())\nf1score = f1_score(y_test,y_pred)\naccuracyscore = accuracy_score(y_test,y_pred)\nprecisionscore = precision_score(y_test,y_pred)\nrecallscore = recall_score(y_test,y_pred)\nprint(f\"f1_score: {f1score}\")\nprint(f\"Accuracy: {accuracyscore}\")\nprint(f\"Precision: {precisionscore}\")\nprint(f\"Recall: {recallscore}\")\nprint('Time Taken :' + str(round(start - time.time(),2) * -1))\nprint(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:28:59.336182Z","iopub.execute_input":"2021-05-26T07:28:59.336524Z","iopub.status.idle":"2021-05-26T07:29:03.657748Z","shell.execute_reply.started":"2021-05-26T07:28:59.336481Z","shell.execute_reply":"2021-05-26T07:29:03.656712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.6 XGBoost","metadata":{}},{"cell_type":"markdown","source":"XGBoost是陈天奇等人开发的一个开源机器学习项目，高效地实现了GBDT算法并进行了算法和工程上的许多改进","metadata":{}},{"cell_type":"code","source":"print(f\"**********XGBoost**********\")\nmodel = XGBClassifier()\nstart = time.time()\nmodel.fit(np.asarray(x_train.to_list()),y_train)\ny_pred = model.predict(np.asarray(x_test.to_list()))\nf1score = f1_score(y_test,y_pred)\naccuracyscore = accuracy_score(y_test,y_pred)\nprecisionscore = precision_score(y_test,y_pred)\nrecallscore = recall_score(y_test,y_pred)\nprint(f\"f1_score: {f1score}\")\nprint(f\"Accuracy: {accuracyscore}\")\nprint(f\"Precision: {precisionscore}\")\nprint(f\"Recall: {recallscore}\")\nprint('Time Taken :' + str(round(start - time.time(),2) * -1))\nprint(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:29:03.65897Z","iopub.execute_input":"2021-05-26T07:29:03.659235Z","iopub.status.idle":"2021-05-26T07:29:10.090246Z","shell.execute_reply.started":"2021-05-26T07:29:03.65921Z","shell.execute_reply":"2021-05-26T07:29:10.089077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.7支持向量分类器","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.svm import LinearSVC\nprint(f\"**********SVC**********\")\nmodel = SVC()\nstart = time.time()\nmodel.fit(x_train.to_list(),y_train)\ny_pred = model.predict(x_test.to_list())\nf1score = f1_score(y_test,y_pred)\naccuracyscore = accuracy_score(y_test,y_pred)\nprecisionscore = precision_score(y_test,y_pred)\nrecallscore = recall_score(y_test,y_pred)\nprint(f\"f1_score: {f1score}\")\nprint(f\"Accuracy: {accuracyscore}\")\nprint(f\"Precision: {precisionscore}\")\nprint(f\"Recall: {recallscore}\")\nprint('Time Taken :' + str(round(start - time.time(),2) * -1))\nprint(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:29:10.091803Z","iopub.execute_input":"2021-05-26T07:29:10.092179Z","iopub.status.idle":"2021-05-26T07:29:13.256108Z","shell.execute_reply.started":"2021-05-26T07:29:10.092144Z","shell.execute_reply":"2021-05-26T07:29:13.255019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.8 Stacking","metadata":{}},{"cell_type":"markdown","source":"Stacking 就是当用初始训练数据学习出若干个基学习器后，将这几个学习器的预测结果作为新的训练集，来学习一个新的学习器。","metadata":{}},{"cell_type":"code","source":"print(\"**********Stacking**********\")\nstart = time.time()\nestimators = [(\"xgb\", XGBClassifier()), (\"SVC\",SVC()), (\"rfe\",RandomForestClassifier())]\nfinal_estimator = LinearSVC()\nstacking_clf = StackingClassifier(estimators=estimators, final_estimator=final_estimator)\nstacking_clf.fit(np.asarray(x_train.to_list()),y_train)\ny_pred = stacking_clf.predict(np.asarray(x_test.to_list()))\nf1score = f1_score(y_test,y_pred)\naccuracyscore = accuracy_score(y_test,y_pred)\nprecisionscore = precision_score(y_test,y_pred)\nrecallscore = recall_score(y_test,y_pred)\nprint(f\"f1_score: {f1score}\")\nprint(f\"Accuracy: {accuracyscore}\")\nprint(f\"Precision: {precisionscore}\")\nprint(f\"Recall: {recallscore}\")\nprint('Time Taken :' + str(round(start - time.time(),2) * -1))\nprint(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:29:13.257635Z","iopub.execute_input":"2021-05-26T07:29:13.258077Z","iopub.status.idle":"2021-05-26T07:30:24.947138Z","shell.execute_reply.started":"2021-05-26T07:29:13.258031Z","shell.execute_reply":"2021-05-26T07:30:24.946081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. 人工神经网络(ANNs)","metadata":{}},{"cell_type":"markdown","source":"ANNs又称连接模型（connection model），它是一种模仿动物神经网络行为特征，进行分布式并行信息处理的数学模型。它是由一系列简单的单元相互密集连接构成的，其中每一个单元有一定数量的实值输入，并产生单一的实数值输出。","metadata":{}},{"cell_type":"markdown","source":"## 8.1 停止函数","metadata":{}},{"cell_type":"code","source":"class myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch,logs={}):\n    if(logs.get('accuracy')>0.90):\n      print(\"\\nReached 90% accuracy so cancelling training\")\n      self.model.stop_training=True","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:30:24.94877Z","iopub.execute_input":"2021-05-26T07:30:24.949204Z","iopub.status.idle":"2021-05-26T07:30:24.955289Z","shell.execute_reply.started":"2021-05-26T07:30:24.949156Z","shell.execute_reply":"2021-05-26T07:30:24.954077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8.2创建模型","metadata":{}},{"cell_type":"code","source":"callbacks = myCallback()\nann_model = tf.keras.models.Sequential([\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(32, activation=tf.nn.relu),\n    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n])\nann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[\"accuracy\"])\nann_model.fit(np.asarray(x_train.to_list()), y_train, epochs=1000, validation_data=(np.asarray(x_test.to_list()), y_test), callbacks=[callbacks])\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:30:24.957051Z","iopub.execute_input":"2021-05-26T07:30:24.957572Z","iopub.status.idle":"2021-05-26T07:30:35.82035Z","shell.execute_reply.started":"2021-05-26T07:30:24.957521Z","shell.execute_reply":"2021-05-26T07:30:35.819336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8.3评估ANN","metadata":{}},{"cell_type":"code","source":"ann_model.evaluate(np.asarray(x_test.to_list()),y_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:30:35.825832Z","iopub.execute_input":"2021-05-26T07:30:35.826156Z","iopub.status.idle":"2021-05-26T07:30:35.936212Z","shell.execute_reply.started":"2021-05-26T07:30:35.826121Z","shell.execute_reply":"2021-05-26T07:30:35.935368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 9.LSTM的准备","metadata":{}},{"cell_type":"markdown","source":"长短期记忆（Long short-term memory, LSTM）是一种特殊的RNN，主要是为了解决长序列训练过程中的梯度消失和梯度爆炸问题。简单来说，就是相比普通的RNN，LSTM能够在更长的序列中有更好的表现","metadata":{}},{"cell_type":"markdown","source":"## 9.1创建词频","metadata":{}},{"cell_type":"code","source":"processed_train_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:30:35.938391Z","iopub.execute_input":"2021-05-26T07:30:35.938678Z","iopub.status.idle":"2021-05-26T07:30:35.949672Z","shell.execute_reply.started":"2021-05-26T07:30:35.93865Z","shell.execute_reply":"2021-05-26T07:30:35.948582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def counter_word(text):\n    count = Counter()\n    for i in text.values:\n        for word in i.split():\n            count[word] += 1\n    return count","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:30:35.951389Z","iopub.execute_input":"2021-05-26T07:30:35.951822Z","iopub.status.idle":"2021-05-26T07:30:35.962009Z","shell.execute_reply.started":"2021-05-26T07:30:35.951777Z","shell.execute_reply":"2021-05-26T07:30:35.960845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counter = counter_word(processed_train_df.text)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:30:35.963345Z","iopub.execute_input":"2021-05-26T07:30:35.963678Z","iopub.status.idle":"2021-05-26T07:30:36.006651Z","shell.execute_reply.started":"2021-05-26T07:30:35.963647Z","shell.execute_reply":"2021-05-26T07:30:36.005309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_words = len(counter)\n#Max number of words in a sequence\nmax_length = 30","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:30:36.008058Z","iopub.execute_input":"2021-05-26T07:30:36.008424Z","iopub.status.idle":"2021-05-26T07:30:36.013929Z","shell.execute_reply.started":"2021-05-26T07:30:36.008387Z","shell.execute_reply":"2021-05-26T07:30:36.012456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 9.2创建训练集和测试集拆分","metadata":{}},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(processed_train_df[\"text\"],processed_train_df[\"target\"],test_size=0.3)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:30:36.015471Z","iopub.execute_input":"2021-05-26T07:30:36.015903Z","iopub.status.idle":"2021-05-26T07:30:36.027947Z","shell.execute_reply.started":"2021-05-26T07:30:36.015858Z","shell.execute_reply":"2021-05-26T07:30:36.026942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 9.3词汇索引","metadata":{}},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words = num_words)\ntokenizer.fit_on_texts(x_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:30:36.029317Z","iopub.execute_input":"2021-05-26T07:30:36.02976Z","iopub.status.idle":"2021-05-26T07:30:36.142008Z","shell.execute_reply.started":"2021-05-26T07:30:36.029714Z","shell.execute_reply":"2021-05-26T07:30:36.140974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_index = tokenizer.word_index","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:30:36.143169Z","iopub.execute_input":"2021-05-26T07:30:36.143604Z","iopub.status.idle":"2021-05-26T07:30:36.148485Z","shell.execute_reply.started":"2021-05-26T07:30:36.143563Z","shell.execute_reply":"2021-05-26T07:30:36.147386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 9.4创建词序","metadata":{}},{"cell_type":"code","source":"train_sequences = tokenizer.texts_to_sequences(x_train)\ntrain_sequences[:5]","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:30:36.149946Z","iopub.execute_input":"2021-05-26T07:30:36.150531Z","iopub.status.idle":"2021-05-26T07:30:36.238378Z","shell.execute_reply.started":"2021-05-26T07:30:36.150487Z","shell.execute_reply":"2021-05-26T07:30:36.23727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 9.5文本填充","metadata":{}},{"cell_type":"code","source":"train_padded = pad_sequences(\n    train_sequences, maxlen= max_length, padding='post', truncating = 'post'\n)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:30:36.239777Z","iopub.execute_input":"2021-05-26T07:30:36.24021Z","iopub.status.idle":"2021-05-26T07:30:36.286784Z","shell.execute_reply.started":"2021-05-26T07:30:36.240164Z","shell.execute_reply":"2021-05-26T07:30:36.285625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sequences = tokenizer.texts_to_sequences(x_test)\ntest_sequences[:5]","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:30:36.288039Z","iopub.execute_input":"2021-05-26T07:30:36.28849Z","iopub.status.idle":"2021-05-26T07:30:36.3343Z","shell.execute_reply.started":"2021-05-26T07:30:36.288445Z","shell.execute_reply":"2021-05-26T07:30:36.333419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_padded = pad_sequences(\n    test_sequences, maxlen= max_length, padding='post', truncating = 'post'\n)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:30:36.33559Z","iopub.execute_input":"2021-05-26T07:30:36.335929Z","iopub.status.idle":"2021-05-26T07:30:36.358125Z","shell.execute_reply.started":"2021-05-26T07:30:36.3359Z","shell.execute_reply":"2021-05-26T07:30:36.35717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train.head(1))\nprint(train_sequences[0])","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:30:36.359412Z","iopub.execute_input":"2021-05-26T07:30:36.359681Z","iopub.status.idle":"2021-05-26T07:30:36.369179Z","shell.execute_reply.started":"2021-05-26T07:30:36.359655Z","shell.execute_reply":"2021-05-26T07:30:36.368196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 10.建立LSTM模型","metadata":{}},{"cell_type":"markdown","source":"## 10.1 停止函数","metadata":{}},{"cell_type":"code","source":"class myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch,logs={}):\n    if(logs.get('accuracy')>=0.85):\n      print(\"\\nReached 85% accuracy so cancelling training\")\n      self.model.stop_training=True\ncallbacks = myCallback()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:30:36.370268Z","iopub.execute_input":"2021-05-26T07:30:36.370558Z","iopub.status.idle":"2021-05-26T07:30:36.377534Z","shell.execute_reply.started":"2021-05-26T07:30:36.370531Z","shell.execute_reply":"2021-05-26T07:30:36.376498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 10.2创建模型","metadata":{}},{"cell_type":"code","source":"lstm_model = tf.keras.models.Sequential([\n    tf.keras.layers.Embedding(num_words, 32, input_length=max_length),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.LSTM(200),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(64, activation=\"relu\"),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(32, activation=\"relu\"),\n    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n])\n\nlstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:30:36.378812Z","iopub.execute_input":"2021-05-26T07:30:36.379087Z","iopub.status.idle":"2021-05-26T07:30:36.703183Z","shell.execute_reply.started":"2021-05-26T07:30:36.379062Z","shell.execute_reply":"2021-05-26T07:30:36.702386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = lstm_model.fit(\n    train_padded,\n    y_train,\n    epochs=30,\n    verbose=1,\n    validation_data=(test_padded, y_test),\n    callbacks=[callbacks]\n)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:30:36.704431Z","iopub.execute_input":"2021-05-26T07:30:36.704929Z","iopub.status.idle":"2021-05-26T07:31:08.823706Z","shell.execute_reply.started":"2021-05-26T07:30:36.704898Z","shell.execute_reply":"2021-05-26T07:31:08.822628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 10.3评估LSTM","metadata":{}},{"cell_type":"code","source":"lstm_model.evaluate(test_padded,y_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:31:08.825386Z","iopub.execute_input":"2021-05-26T07:31:08.825697Z","iopub.status.idle":"2021-05-26T07:31:10.204052Z","shell.execute_reply.started":"2021-05-26T07:31:08.825667Z","shell.execute_reply":"2021-05-26T07:31:10.20293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 11.输出","metadata":{}},{"cell_type":"markdown","source":"## 11.1预处理测试数据集","metadata":{}},{"cell_type":"code","source":"def clean_text(text):\n    text = uncapitalize(text)\n    text = removeEmojis(text)\n    text = expand_abbr(text)\n    text = strip_links(text)\n    text = strip_all_entities(text)\n    text = lemmatize_with_postag(text)\n    cleaned_tokens = remove_stopwords(text)\n    final_text = remove_punctuation(cleaned_tokens)\n    return final_text\n\nprocessed_test_df = test_df.copy(deep=True)\nprocessed_test_df[\"text\"] = processed_test_df.text.apply(clean_text)\n\nfinal_train_df = train_df.copy(deep=True)\nfinal_train_df[\"text\"] = final_train_df.text.apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:31:10.205604Z","iopub.execute_input":"2021-05-26T07:31:10.206027Z","iopub.status.idle":"2021-05-26T07:31:32.457154Z","shell.execute_reply.started":"2021-05-26T07:31:10.205981Z","shell.execute_reply":"2021-05-26T07:31:32.455959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 11.2将文本转换为向量","metadata":{}},{"cell_type":"code","source":"test_embedding_df = processed_test_df.copy(deep=True)\ntest_embedding_df[\"text\"] = test_embedding_df.text.apply(get_sentence_vectors)\n\nfinal_train_embedding = final_train_df.copy(deep=True)\nfinal_train_embedding[\"text\"] = final_train_embedding.text.apply(get_sentence_vectors)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:31:32.458429Z","iopub.execute_input":"2021-05-26T07:31:32.458735Z","iopub.status.idle":"2021-05-26T07:31:32.761511Z","shell.execute_reply.started":"2021-05-26T07:31:32.458701Z","shell.execute_reply":"2021-05-26T07:31:32.760468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_train_embedding.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:31:32.762761Z","iopub.execute_input":"2021-05-26T07:31:32.763039Z","iopub.status.idle":"2021-05-26T07:31:32.783828Z","shell.execute_reply.started":"2021-05-26T07:31:32.763012Z","shell.execute_reply":"2021-05-26T07:31:32.782649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 11.3输出预测","metadata":{}},{"cell_type":"code","source":"estimators = [(\"xgb\", XGBClassifier()), (\"SVC\",SVC()), (\"rfe\",RandomForestClassifier())]\nfinal_estimator = LinearSVC()\nstacking_clf = StackingClassifier(estimators=estimators, final_estimator=final_estimator)\nstacking_clf.fit(np.asarray(final_train_embedding[\"text\"].to_list()),final_train_embedding[\"target\"])\npredictions = stacking_clf.predict(np.asarray(test_embedding_df[\"text\"].to_list()))","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:31:32.785079Z","iopub.execute_input":"2021-05-26T07:31:32.785637Z","iopub.status.idle":"2021-05-26T07:33:06.517927Z","shell.execute_reply.started":"2021-05-26T07:31:32.78559Z","shell.execute_reply":"2021-05-26T07:33:06.516256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_df = pd.Series(np.array(predictions).flatten()).to_frame()\nresult_df = pd.concat([test_df,predictions_df], axis = 1)\nresult_df.drop(columns=['text'], axis=1, inplace=True)\nresult_df = result_df.rename(columns={0: \"target\"})\nresult_df['target'] = result_df['target'].map(lambda a: int(a))","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:33:06.519879Z","iopub.execute_input":"2021-05-26T07:33:06.520608Z","iopub.status.idle":"2021-05-26T07:33:06.540878Z","shell.execute_reply.started":"2021-05-26T07:33:06.520555Z","shell.execute_reply":"2021-05-26T07:33:06.539484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:33:06.542918Z","iopub.execute_input":"2021-05-26T07:33:06.543555Z","iopub.status.idle":"2021-05-26T07:33:06.55739Z","shell.execute_reply.started":"2021-05-26T07:33:06.543503Z","shell.execute_reply":"2021-05-26T07:33:06.555928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_df.to_csv('result.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:33:06.559221Z","iopub.execute_input":"2021-05-26T07:33:06.560041Z","iopub.status.idle":"2021-05-26T07:33:06.585491Z","shell.execute_reply.started":"2021-05-26T07:33:06.559987Z","shell.execute_reply":"2021-05-26T07:33:06.584189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}